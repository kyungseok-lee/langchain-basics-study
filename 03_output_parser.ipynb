{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f61c136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kyungseok.lee/workspace-git/langchain-basics-study/.venv/bin/python: No module named uv\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 1단계: 필요한 패키지 설치\n",
    "%uv pip install -q langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b24eb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2단계: LLM 모델 초기화\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"gemma3:1b\")\n",
    "print(\"✅ LLM 모델이 초기화되었습니다.\")\n",
    "\n",
    "# Invalid input type <class 'int'>. Must be a PromptValue, str, or list of BaseMessages.\n",
    "# llm.invoke(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91b5fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='What is the capital of France? Return the name of the city only'\n",
      "content='Paris' additional_kwargs={} response_metadata={'model': 'gemma3:1b', 'created_at': '2025-09-05T16:41:01.125648Z', 'done': True, 'done_reason': 'stop', 'total_duration': 206790042, 'load_duration': 143706667, 'prompt_eval_count': 23, 'prompt_eval_duration': 47603958, 'eval_count': 2, 'eval_duration': 14971584, 'model_name': 'gemma3:1b'} id='run--c82bf991-c4da-4315-9325-9d22d38179ae-0' usage_metadata={'input_tokens': 23, 'output_tokens': 2, 'total_tokens': 25}\n",
      "Paris\n"
     ]
    }
   ],
   "source": [
    "# 3단계: 기본 출력 파서 사용 예시\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"What is the capital of {country}? Return the name of the city only\",\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "\n",
    "prompt = prompt_template.invoke({\"country\": \"France\"})\n",
    "print(\"프롬프트:\", prompt)\n",
    "\n",
    "ai_message = llm.invoke(prompt_template.invoke({\"country\": \"France\"}))\n",
    "print(\"AI 응답:\", ai_message)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "answer = output_parser.invoke(llm.invoke(prompt_template.invoke({\"country\": \"France\"})))\n",
    "print(\"파싱된 답변:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c03ee0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Paris', additional_kwargs={}, response_metadata={'model': 'gemma3:1b', 'created_at': '2025-09-05T16:38:03.727889Z', 'done': True, 'done_reason': 'stop', 'total_duration': 778530042, 'load_duration': 652395250, 'prompt_eval_count': 23, 'prompt_eval_duration': 113322459, 'eval_count': 2, 'eval_duration': 12208125, 'model_name': 'gemma3:1b'}, id='run--7d253e8f-0df9-413b-94dc-2b1d535e4cfa-0', usage_metadata={'input_tokens': 23, 'output_tokens': 2, 'total_tokens': 25})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ef92622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paris'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37e31fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class CountryDetail(BaseModel):\n",
    "    capital: str = Field(description=\"The capital of the country\")\n",
    "    population: int = Field(description=\"The population of the country\")\n",
    "    language: str = Field(description=\"The language of the country\")\n",
    "    currency: str = Field(description=\"The currency of the country\")\n",
    "\n",
    "structured_llm= llm.with_structured_output(CountryDetail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90afc209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "# from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "country_detail_prompt = PromptTemplate(\n",
    "    template=\"\"\"Give following information about {country}:\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    return it in JSON format. and return the JSON dictionary only\n",
    "    \"\"\",\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "\n",
    "# JsonOutputParser는 잘 동작하지 않음.\n",
    "# country_detail_prompt.invoke({\"country\": \"France\"})\n",
    "# output_parser = JsonOutputParser()\n",
    "# print(json_ai_message.content)\n",
    "\n",
    "json_ai_message = structured_llm.invoke(country_detail_prompt.invoke({\"country\": \"France\"}))\n",
    "\n",
    "# output_parser.invoke(json_ai_message)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd6adf08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountryDetail(capital='Paris', population=6773000, language='French', currency='Euro')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(json_ai_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
