# LangChain ê¸°ë³¸ê¸° í•™ìŠµ ë…¸íŠ¸

## ğŸ“š ê°•ì˜ ì •ë³´
- **ê°•ì˜ëª…**: í•œì‹œê°„ìœ¼ë¡œ ëë‚´ëŠ” LangChain ê¸°ë³¸ê¸°

## ğŸ“– í•™ìŠµ ëª©ì°¨
### LLMì„ í™œìš©í•´ì„œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë°©ë²•

ollama í™ˆí˜ì´ì§€ì—ì„œ app ë‹¤ìš´ë¡œë“œ ë˜ëŠ” brewë¡œ ì„¤ì¹˜
```bash
brew install ollama
ollama pull gemma3:1b
ollama serve
```

ollama ì‚¬ìš©ë²• ì°¸ê³ 
```bash
Usage:
  ollama [flags]
  ollama [command]

Available Commands:
  serve       Start ollama
  create      Create a model
  show        Show information for a model
  run         Run a model
  stop        Stop a running model
  pull        Pull a model from a registry
  push        Push a model to a registry
  list        List models
  ps          List running models
  cp          Copy a model
  rm          Remove a model
  help        Help about any command

Flags:
  -h, --help      help for ollama
  -v, --version   Show version information

Use "ollama [command] --help" for more information about a command.
```

#### python ê°€ìƒ í™˜ê²½ ì„¤ì •
ê°•ì˜ì—ì„  pyenvë¥¼ ì‚¬ìš©í–ˆìœ¼ë‚˜ uvë¡œ ëŒ€ì²´í•¨
```bash
uv venv --python 3.11.9 .venv
source .venv/bin/activate
uv pip install --upgrade pip setuptools wheel

python -V                     # Python 3.11.9
python -m pip --version
```

#### 1. Ollamaë¥¼ í™œìš©í•œ ë¡œì»¬ LLM ì‚¬ìš©

```python
# langchain-ollama íŒ¨í‚¤ì§€ ì„¤ì¹˜
%pip install -q langchain-ollama

# ChatOllamaì„ ì‚¬ìš©í•œ ë¡œì»¬ ëª¨ë¸ í˜¸ì¶œ
from langchain_ollama import ChatOllama

llm = ChatOllama(model="gemma3:1b")
response = llm.invoke("ë„ˆëŠ” ëˆ„êµ¬ëƒ?")

# ì‘ë‹µ ì˜ˆì‹œ:
# AIMessage(content='ì €ëŠ” Google DeepMindì—ì„œ í›ˆë ¨í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤.', 
#           additional_kwargs={}, 
#           response_metadata={'model': 'gemma3:1b', 'created_at': '2025-08-30T22:03:57.432788Z', 'done': True, 'done_reason': 'stop', 'total_duration': 237999125, 'load_duration': 91485041, 'prompt_eval_count': 14, 'prompt_eval_duration': 31124917, 'eval_count': 16, 'eval_duration': 114957250, 'model_name': 'gemma3:1b'}, 
#           id='run--669fd310-5541-4378-838a-60c3e57033e6-0', 
#           usage_metadata={'input_tokens': 14, 'output_tokens': 16, 'total_tokens': 30})
```

#### 2. OpenAI APIë¥¼ í™œìš©í•œ í´ë¼ìš°ë“œ LLM ì‚¬ìš©

```python
# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
%pip install -q langchain-openai python-dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

# ChatOpenAIì„ ì‚¬ìš©í•œ OpenAI ëª¨ë¸ í˜¸ì¶œ
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4o-mini")  # OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ í•„ìš”
response = llm.invoke("ë„ˆëŠ” ëˆ„êµ¬ëƒ?")

# ì‘ë‹µ ì˜ˆì‹œ:
# AIMessage(content='ì €ëŠ” OpenAIì—ì„œ ê°œë°œí•œ ì¸ê³µì§€ëŠ¥ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ë‹µí•˜ê±°ë‚˜ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ë° ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?', 
#           additional_kwargs={'refusal': None}, 
#           response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 12, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CANy3k9BvSD6ik1TSsYgfSnCx78oB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, 
#           id='run--9e87536c-a51a-490b-8fd9-36efe9c51f3f-0', 
#           usage_metadata={'input_tokens': 12, 'output_tokens': 38, 'total_tokens': 50, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})
```

#### 3. Azure OpenAI ì‚¬ìš© (ì£¼ì˜ì‚¬í•­)

```python
# Azure OpenAI ì‚¬ìš© ì‹œ ì˜¬ë°”ë¥¸ ì„¤ì • í•„ìš”
from langchain_openai import AzureOpenAI

# ì˜¬ë°”ë¥¸ ì„¤ì • ì˜ˆì‹œ:
llm = AzureOpenAI(
    azure_deployment="your-deployment-name",  # Azure ë°°í¬ ì´ë¦„
    openai_api_version="2024-02-15-preview",  # API ë²„ì „
    azure_endpoint="https://your-resource.openai.azure.com/"  # Azure ì—”ë“œí¬ì¸íŠ¸
)

# ì˜ëª»ëœ ì„¤ì •ìœ¼ë¡œ ì¸í•œ ì˜¤ë¥˜:
# APIConnectionError: Connection error.
# UnsupportedProtocol: Request URL is missing an 'http://' or 'https://' protocol.
```

#### 4. ì£¼ìš” ì°¨ì´ì  ë° íŠ¹ì§•

| êµ¬ë¶„ | Ollama (ë¡œì»¬) | OpenAI (í´ë¼ìš°ë“œ) | Azure OpenAI |
|------|----------------|-------------------|--------------|
| **ì„¤ì¹˜** | ë¡œì»¬ ì„¤ì¹˜ í•„ìš” | API í‚¤ë§Œ í•„ìš” | Azure ë¦¬ì†ŒìŠ¤ í•„ìš” |
| **ë¹„ìš©** | ë¬´ë£Œ | í† í°ë‹¹ ê³¼ê¸ˆ | Azure ì‚¬ìš©ëŸ‰ ê³¼ê¸ˆ |
| **ì„±ëŠ¥** | í•˜ë“œì›¨ì–´ ì˜ì¡´ | ê³ ì„±ëŠ¥ | ê³ ì„±ëŠ¥ |
| **í”„ë¼ì´ë²„ì‹œ** | ì™„ì „ ë¡œì»¬ | OpenAI ì„œë²„ | Azure ì„œë²„ |
| **ëª¨ë¸** | ì œí•œì  | ë‹¤ì–‘í•œ ëª¨ë¸ | OpenAI ëª¨ë¸ |

#### 5. í™˜ê²½ ì„¤ì • ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Python 3.11.9 ì´ìƒ ì„¤ì¹˜ (uv ì‚¬ìš© ê¶Œì¥)
- [ ] ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™” (`uv venv --python 3.11.9 .venv`)
- [ ] í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (langchain-ollama, langchain-openai, python-dotenv)
- [ ] í™˜ê²½ë³€ìˆ˜ ì„¤ì • (.env íŒŒì¼)
- [ ] Ollama ì„œë¹„ìŠ¤ ì‹¤í–‰ (ë¡œì»¬ ëª¨ë¸ ì‚¬ìš© ì‹œ)
- [ ] API í‚¤ ì„¤ì • (í´ë¼ìš°ë“œ ëª¨ë¸ ì‚¬ìš© ì‹œ)

### ë­ì²´ì¸ ìŠ¤íƒ€ì¼ë¡œ í”„ë¡¬í”„íŠ¸ ì‘ì„±í•˜ëŠ” ë°©ë²•

### ë‹µë³€ì˜ í˜•ì‹ì„ ì»¨íŠ¸ë¡¤í•˜ëŠ” ë°©ë²•

### LCELì„ í™œìš©í•œ ë­"ì²´ì¸" ìƒì„±í•˜ëŠ” ë°©ë²•

### ì§€ê¸ˆê¹Œì§€ ë°°ìš´ ë‚´ìš© ì´ì •ë¦¬ (feat. í”„ë¡¬í”„íŠ¸ ê¿€íŒ ì‚´ì§)

### ë­ì²´ì¸ì„ í™œìš©í•´ì„œ í•  ìˆ˜ ìˆëŠ” ê²ƒë“¤
